{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4fdaee-6221-4923-b17b-f7df23bb1015",
   "metadata": {},
   "source": [
    "# S&P 500 Ranking Project\n",
    "## Python, SQL and Tableau: Linear Regression, Key Metrics, Dashboard\n",
    "- Data Source: Yahoo Finance\n",
    "- Import Tool: Yfinance \n",
    "- Export Option: SQL database\n",
    "- Data Transformations: drop /edit cols, create features for regression analysis\n",
    "- Future changes: Add portfolio risk analysis, Agg. economic health indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1e43f1-f12a-4783-aa30-57f419efa4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from tqdm import notebook\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa6f9a0-62e3-40fc-9ba0-844c0529c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current directory\n",
    "os.chdir('/home/jovyan/work')\n",
    "\n",
    "# Pandas settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Constants\n",
    "tickers_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1349f7bc-121b-483f-b9a9-6f975076a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch S&P 500 ticker list\n",
    "def read_tickers():    \n",
    "    page = requests.get(tickers_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "    \n",
    "    # Fail now if we haven't found the right table\n",
    "    header = table.findAll(\"th\")\n",
    "    if header[0].text.rstrip() != \"Symbol\" or header[1].string != \"Security\":\n",
    "        raise Exception(\"Can't parse Wikipedia's table!\")\n",
    "    \n",
    "    ticker_arr = []\n",
    "    rows = table.findAll(\"tr\")\n",
    "    for row in rows:\n",
    "        fields = row.findAll(\"td\")\n",
    "        if fields:\n",
    "            ticker = fields[0].text.rstrip().replace('.','-')\n",
    "            ticker_arr.append(ticker)\n",
    "\n",
    "    ticker_str = ' '.join(ticker_arr)\n",
    "\n",
    "    return ticker_str, ticker_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825c188d-e77e-4c73-9c70-74174b04e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tickers and init yahoo finance scraper\n",
    "tickers, ticker_arr = read_tickers()\n",
    "sp500 = yf.Tickers(tickers)\n",
    "\n",
    "ticker_range = int(len(ticker_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac9c2a0-a64b-406b-8e08-19a4397d2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract\n",
    "\n",
    "def extract_info(yfd):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in notebook.tqdm(range(ticker_range), total=ticker_range):\n",
    "        data = yfd.tickers.get(ticker_arr[i]).info\n",
    "        partial = pd.json_normalize(data, max_level=1)\n",
    "        df = pd.concat([df,partial], ignore_index=True, sort=False)\n",
    "    print('Load company info data successful')\n",
    "    return df\n",
    "\n",
    "def transform_helper(partial,i,T=True):\n",
    "    if T:\n",
    "        partial = partial.T\n",
    "    partial.reset_index(inplace=True)\n",
    "    partial.columns = ['Date', *partial.columns[1:]]\n",
    "    partial['Ticker'] = ticker_arr[i]\n",
    "\n",
    "    try:\n",
    "        partial['Date'] = pd.to_datetime(partial['Date']).dt.date\n",
    "    except:\n",
    "        partial['Date'] = np.nan\n",
    "    return partial\n",
    "\n",
    "def get_income(yfd):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in notebook.tqdm(range(ticker_range), total=ticker_range):\n",
    "        org = yfd.tickers.get(ticker_arr[i]).financials\n",
    "        partial = transform_helper(org.copy(),i)\n",
    "        df = pd.concat([df,partial], ignore_index=True, sort=False)\n",
    "    print('Load company income statement data successful')\n",
    "    return df\n",
    "\n",
    "def get_balance_sheet(yfd):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in notebook.tqdm(range(ticker_range), total=ticker_range):\n",
    "        org = yfd.tickers.get(ticker_arr[i]).balance_sheet\n",
    "        partial = transform_helper(org.copy(),i)\n",
    "        df = pd.concat([df,partial], ignore_index=True, sort=False)\n",
    "    print('Load company balance sheet data successful')\n",
    "    return df\n",
    "\n",
    "def get_cash_flow(yfd):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in notebook.tqdm(range(ticker_range), total=ticker_range):\n",
    "        org = yfd.tickers.get(ticker_arr[i]).cashflow\n",
    "        partial = transform_helper(org.copy(),i)\n",
    "        df = pd.concat([df,partial], ignore_index=True, sort=False)\n",
    "    print('Load company cashflow statement data successful')\n",
    "    return df\n",
    "\n",
    "def extract_financials(yfd):\n",
    "    df_pnl = get_income(yfd)\n",
    "    df_bs = get_balance_sheet(yfd)\n",
    "    df_cf = get_cash_flow(yfd)\n",
    "    return df_pnl, df_bs, df_cf\n",
    "\n",
    "def extract_recommendations(yfd):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in notebook.tqdm(range(ticker_range), total=ticker_range):\n",
    "        org = yfd.tickers.get(ticker_arr[i]).recommendations\n",
    "        partial = transform_helper(org.copy(),i,T=False)\n",
    "        twoQs = pd.to_datetime('today').date() - timedelta(weeks=26)\n",
    "        partial = partial[partial['Date'] > twoQs]\n",
    "        df = pd.concat([df,partial],ignore_index=True, sort=False)\n",
    "    print('Load company recommendation data successful')\n",
    "    return df\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87e44a2-e333-4ca5-be7b-b0565fb786bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6b4f039e864fff98a6af6dc669a8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company info data successful\n"
     ]
    }
   ],
   "source": [
    "df1 = extract_info(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39394546-5553-4b5d-b91e-42765aee6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882b7eb8db97418cbb302af47e2d7c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company income statement data successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c931379c594048c38d4bb48c712dde8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company balance sheet data successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c7234e0ba414ba13cd7ba9157f01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company cashflow statement data successful\n"
     ]
    }
   ],
   "source": [
    "df2, df3, df4 = extract_financials(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5d35bc-bb01-4090-91d3-843dbb78a9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa374112f2654aaba2e20dad410defec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company recommendation data successful\n"
     ]
    }
   ],
   "source": [
    "df5 = extract_recommendations(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f50bd1-f628-488e-9541-bef7749caa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 cleaning successful\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "\n",
    "# drop empty or unecessary cols\n",
    "null_cols = df1.isna().sum() >500\n",
    "drop_cols = null_cols.loc[lambda x : x == True]\n",
    "df1.drop(columns=drop_cols.index.array, inplace=True)\n",
    "df1.drop(columns=['maxAge','fax','quoteType',\n",
    "                  # '52WeekChange', 'SandP52WeekChange', 'impliedSharesOutstanding', 'trailingPegRatio'\n",
    "                 'tradeable','address2','companyOfficers','priceHint',\n",
    "                 'financialCurrency','exchangeTimezoneName','exchangeTimezoneShortName',\n",
    "                 'market','uuid','targetLowPrice','recommendationKey','targetMedianPrice',\n",
    "                 'numberOfAnalystOpinions','targetMeanPrice','targetHighPrice','recommendationMean',\n",
    "                 'gmtOffSetMilliseconds'], inplace=True)\n",
    "print(\"df1 cleaning successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2652668d-7e37-4221-a90a-10d5f2bc1d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d003adf7049f4b96bae4844a95d2d74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company income statement data successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed66a7d25844128bbc1a1e278dae029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company balance sheet data successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5934e77e25374227bb497297f247d021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load company cashflow statement data successful\n"
     ]
    }
   ],
   "source": [
    "# run any test now\n",
    "redo_arr = df4[df4['Date'].isna()]['Ticker'].unique().tolist()\n",
    "if len(redo_arr) > 0:\n",
    "    redo = ' '.join(redo_arr)\n",
    "    missing = yf.Tickers(redo)\n",
    "    ticker_arr = redo_arr\n",
    "    ticker_range = int(len(redo_arr))\n",
    "    \n",
    "    df2r, df3r, df4r = extract_financials(missing)\n",
    "    \n",
    "    df2 = df2[df2['Ticker'].apply(lambda x: x not in redo_arr)]\n",
    "    df2 = pd.concat([df2,df2r],ignore_index=True, sort=False)\n",
    "    df3 = df3[df3['Ticker'].apply(lambda x: x not in redo_arr)]\n",
    "    df3 = pd.concat([df3,df3r],ignore_index=True, sort=False)\n",
    "    df4 = df4[df4['Ticker'].apply(lambda x: x not in redo_arr)]\n",
    "    df4 = pd.concat([df4,df4r],ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1d40de-f350-4657-9787-215d55f6186c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is complete\n"
     ]
    }
   ],
   "source": [
    "# Last check before sql import\n",
    "m1 = len(df2[df2['Date'].isna()]['Ticker'].unique().tolist())>0\n",
    "m2 = len(df3[df3['Date'].isna()]['Ticker'].unique().tolist())>0\n",
    "m3 = len(df4[df4['Date'].isna()]['Ticker'].unique().tolist())>0\n",
    "m4 = len(df5['Ticker'].unique().tolist()) == len(ticker_arr)\n",
    "if not(m1+m2+m3+m4):\n",
    "    print('Dataset is complete')\n",
    "else:\n",
    "    print('Dataset is not complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a2484d0-125e-46a2-a3d6-f7d7014ed835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:headband@192.168.0.151:5432/mydb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "852bd799-4ceb-4cfc-92b1-4eff206b099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "def update_server(table_name,dataframe):  \n",
    "    try:\n",
    "        dataframe.to_sql(table_name,con=engine,index=False,if_exists='replace')\n",
    "        print(f'Successfully imported {table_name} to server')\n",
    "    except Exception as err:\n",
    "        print('Got an error while updating server')\n",
    "        print('Error: ', str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "047f4b06-616a-4fc0-b3a5-e9f7f92d6ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported SP500Info to server\n",
      "Successfully imported SP500Income to server\n",
      "Successfully imported SP500BalanceSheet to server\n",
      "Successfully imported SP500CashFlow to server\n",
      "Successfully imported SP500Recommendation to server\n"
     ]
    }
   ],
   "source": [
    "dfs = [df1,df2,df3,df4,df5]\n",
    "sql_tables = [\"Info\",\"Income\",\"BalanceSheet\",\"CashFlow\",\"Recommendation\"]\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    update_server(f\"SP500{sql_tables[i]}\",dfs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
